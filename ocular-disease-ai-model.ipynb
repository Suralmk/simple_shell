{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.15","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":1512919,"sourceType":"datasetVersion","datasetId":611716}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport os\nimport cv2\nimport numpy as np\nfrom PIL import Image\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.applications import EfficientNetB0\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-03T11:33:24.574744Z","iopub.execute_input":"2024-11-03T11:33:24.575720Z","iopub.status.idle":"2024-11-03T11:33:24.580544Z","shell.execute_reply.started":"2024-11-03T11:33:24.575685Z","shell.execute_reply":"2024-11-03T11:33:24.579419Z"},"trusted":true},"outputs":[],"execution_count":51},{"cell_type":"code","source":"\ndef custom_image_generator(image_directory, image_list, batch_size, target_size=(128, 128)):\n    \n    num_images = len(image_list)\n    while True:  # Infinite loop to keep yielding batches\n        \n        for start in range(0, num_images, batch_size):\n            end = min(start + batch_size, num_images)\n            batch_images = []\n            batch_filenames = image_list[start:end]\n\n            for filename in batch_filenames:\n                img_path = os.path.join(image_directory, filename)\n           \n                with Image.open(img_path) as img:\n                    img = img.resize(target_size)\n                    img = np.array(img)  # Convert to numpy array\n                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n                    img = cv2.equalizeHist(img)  # Histogram equalization\n                    img = cv2.GaussianBlur(img, (5, 5), 0)  # Gaussian blur\n                    img = cv2.fastNlMeansDenoising(img, None, 30, 7, 21)  # Noise reduction\n\n                    img_array = np.expand_dims(img, axis=-1) / 255.0  # Normalize and add channel dimension\n                    batch_images.append(img_array)\n\n            yield np.array(batch_images)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T11:33:30.758462Z","iopub.execute_input":"2024-11-03T11:33:30.759315Z","iopub.status.idle":"2024-11-03T11:33:30.767197Z","shell.execute_reply.started":"2024-11-03T11:33:30.759278Z","shell.execute_reply":"2024-11-03T11:33:30.766168Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"# Load the dataset\ndata = pd.read_csv(\"/kaggle/input/ocular-disease-recognition-odir5k/full_df.csv\")\ndata = data.dropna()\n# Define directories and filename lists for left and right eye images\nos.chdir(\"/kaggle/input/ocular-disease-recognition-odir5k/preprocessed_images\")\nimage_directory = \"/kaggle/input/ocular-disease-recognition-odir5k/preprocessed_images\"\nleft_eye = data['Left-Fundus'].tolist()  # Ordered list for left eye\nright_eye = data['Right-Fundus'].tolist()  # Ordered list for right eye\nprint(len(left_eye))\n\nleft_eye_images = []\nright_eye_images = []\nimg_label = []\nlabels = []\n\nfor i in range(len(left_eye)):\n    if os.path.isfile(left_eye[i]) and os.path.isfile(right_eye[i]):\n            \n            left_eye_images.append(left_eye[i])\n            right_eye_images.append(right_eye[i])\n            img_label.append(right_eye[i].split('.')[0].split('_')[0])\n            labels.append(data[['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']].to_numpy()[i])\n\n\n# Define batch size\nbatch_size = 32","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T11:46:40.152254Z","iopub.execute_input":"2024-11-03T11:46:40.152889Z","iopub.status.idle":"2024-11-03T11:46:44.781699Z","shell.execute_reply.started":"2024-11-03T11:46:40.152859Z","shell.execute_reply":"2024-11-03T11:46:44.780595Z"}},"outputs":[{"name":"stdout","text":"6392\n","output_type":"stream"}],"execution_count":85},{"cell_type":"code","source":"data[['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']].to_numpy()[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T11:45:40.667319Z","iopub.execute_input":"2024-11-03T11:45:40.667983Z","iopub.status.idle":"2024-11-03T11:45:40.674261Z","shell.execute_reply.started":"2024-11-03T11:45:40.667952Z","shell.execute_reply":"2024-11-03T11:45:40.673440Z"}},"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"array([0, 0, 0, 1, 0, 0, 0, 0])"},"metadata":{}}],"execution_count":82},{"cell_type":"code","source":"def combined_generator(left_generator, right_generator, labels, batch_size):\n    num_images = len(labels)\n    while True:\n        for start in range(0, num_images, batch_size):\n            end = min(start + batch_size, num_images)\n            left_batch = next(left_generator)\n            right_batch = next(right_generator)\n\n            # Convert to tensors\n            left_batch_tensor = tf.convert_to_tensor(left_batch, dtype=tf.float32)\n            right_batch_tensor = tf.convert_to_tensor(right_batch, dtype=tf.float32)\n            labels_tensor = tf.convert_to_tensor(labels[start:end], dtype=tf.float32)  # Ensure the correct dtype\n            \n            yield ([left_batch_tensor, right_batch_tensor], labels_tensor)\n\n\n\n# Initialize the left and right eye generators\nleft_eye_generator = custom_image_generator(image_directory, left_eye_images, batch_size)\nright_eye_generator = custom_image_generator(image_directory, right_eye_images, batch_size)\n\n# Combine the two generators with labels\ntrain_generator = combined_generator(left_eye_generator, right_eye_generator, labels, batch_size)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T11:47:01.867113Z","iopub.execute_input":"2024-11-03T11:47:01.868054Z","iopub.status.idle":"2024-11-03T11:47:01.874278Z","shell.execute_reply.started":"2024-11-03T11:47:01.868025Z","shell.execute_reply":"2024-11-03T11:47:01.873415Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"# Define the input shape for grayscale images\ninput_shape = (128, 128, 1)\n\n# Function to build a model branch for each eye\ndef build_eye_branch(input_shape):\n    base_model = EfficientNetB0(include_top=False, weights=None, input_shape=input_shape)\n    x = layers.GlobalAveragePooling2D()(base_model.output)\n    branch_model = models.Model(inputs=base_model.input, outputs=x)\n    return branch_model\n\n# Left eye branch\nleft_eye_input = layers.Input(shape=input_shape, name=\"left_eye_input\")\nleft_eye_branch = build_eye_branch(input_shape)\nleft_eye_features = left_eye_branch(left_eye_input)\n\n# Right eye branch\nright_eye_input = layers.Input(shape=input_shape, name=\"right_eye_input\")\nright_eye_branch = build_eye_branch(input_shape)\nright_eye_features = right_eye_branch(right_eye_input)\n\n# Concatenate features from both eyes\ncombined_features = layers.concatenate([left_eye_features, right_eye_features])\n\n# Fully connected layers for classification\nx = layers.Dense(512, activation=\"relu\")(combined_features)\nx = layers.Dropout(0.3)(x)\noutput = layers.Dense(8, activation=\"sigmoid\")(x)  # 8 diseases, sigmoid for multi-label\n\n# Final model\nmodel = models.Model(inputs=[left_eye_input, right_eye_input], outputs=output)\nmodel.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T11:47:51.399039Z","iopub.execute_input":"2024-11-03T11:47:51.399957Z","iopub.status.idle":"2024-11-03T11:47:52.728446Z","shell.execute_reply.started":"2024-11-03T11:47:51.399916Z","shell.execute_reply":"2024-11-03T11:47:52.727535Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\ndef create_tf_dataset(left_images, right_images, labels, batch_size):\n    def generator():\n        for left_image_path, right_image_path, label_batch in zip(left_images, right_images, labels):\n            # Load images from file paths\n            left_image = img_to_array(load_img(left_image_path, color_mode='grayscale', target_size=(128, 128)))\n            right_image = img_to_array(load_img(right_image_path, color_mode='grayscale', target_size=(128, 128)))\n            \n            # Ensure the images are properly reshaped\n            left_image = np.reshape(left_image, (128, 128, 1))\n            right_image = np.reshape(right_image, (128, 128, 1))\n            \n            # Yield the image pair and the corresponding label\n            yield ([left_image, right_image], label_batch)\n\n    return tf.data.Dataset.from_generator(\n        generator,\n        output_signature=(\n            (tf.TensorSpec(shape=(128, 128, 1), dtype=tf.float32),  # Left eye images\n             tf.TensorSpec(shape=(128, 128, 1), dtype=tf.float32)),  # Right eye images\n            tf.TensorSpec(shape=(8,), dtype=tf.float32)  # Labels (assuming 8 classes)\n        )\n    ).batch(batch_size)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T11:54:15.177594Z","iopub.execute_input":"2024-11-03T11:54:15.178556Z","iopub.status.idle":"2024-11-03T11:54:15.186790Z","shell.execute_reply.started":"2024-11-03T11:54:15.178516Z","shell.execute_reply":"2024-11-03T11:54:15.185960Z"}},"outputs":[],"execution_count":98},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assuming left_eye_images, right_eye_images, labels are defined\ntrain_dataset = create_tf_dataset(\n    left_eye_images[:int(len(left_eye_images) * (1 - validation_split))],\n    right_eye_images[:int(len(right_eye_images) * (1 - validation_split))],\n    labels[:int(len(labels) * (1 - validation_split))],\n    batch_size\n)\n\nvalidation_dataset = create_tf_dataset(\n    left_eye_images[int(len(left_eye_images) * (1 - validation_split)):],\n    right_eye_images[int(len(right_eye_images) * (1 - validation_split)):],\n    labels[int(len(labels) * (1 - validation_split)):],\n    batch_size\n)\n\n# Train the model\nhistory = model.fit(\n    train_dataset,\n    validation_data=validation_dataset,\n    epochs=10\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T11:54:20.202604Z","iopub.execute_input":"2024-11-03T11:54:20.203017Z","iopub.status.idle":"2024-11-03T11:54:20.404973Z","shell.execute_reply.started":"2024-11-03T11:54:20.202988Z","shell.execute_reply":"2024-11-03T11:54:20.402975Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","Cell \u001b[0;32mIn[99], line 17\u001b[0m\n\u001b[1;32m      9\u001b[0m validation_dataset \u001b[38;5;241m=\u001b[39m create_tf_dataset(\n\u001b[1;32m     10\u001b[0m     left_eye_images[\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(left_eye_images) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m validation_split)):],\n\u001b[1;32m     11\u001b[0m     right_eye_images[\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(right_eye_images) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m validation_split)):],\n\u001b[1;32m     12\u001b[0m     labels[\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m validation_split)):],\n\u001b[1;32m     13\u001b[0m     batch_size\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[1;32m     21\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was ((tf.float32, tf.float32), tf.float32), but the yielded element was ([array([[[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       ...,\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]]], dtype=float32), array([[[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       ...,\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]]], dtype=float32)], array([0, 0, 0, 1, 0, 0, 0, 0])).\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 204, in generator_py_func\n    flattened_values = nest.flatten_up_to(output_types, values)\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 237, in flatten_up_to\n    return nest_util.flatten_up_to(\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py\", line 1541, in flatten_up_to\n    return _tf_data_flatten_up_to(shallow_tree, input_tree)\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py\", line 1570, in _tf_data_flatten_up_to\n    _tf_data_assert_shallow_structure(shallow_tree, input_tree)\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py\", line 1444, in _tf_data_assert_shallow_structure\n    _tf_data_assert_shallow_structure(\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py\", line 1414, in _tf_data_assert_shallow_structure\n    raise TypeError(\n\nTypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: 'list'.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 206, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was ((tf.float32, tf.float32), tf.float32), but the yielded element was ([array([[[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       ...,\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]]], dtype=float32), array([[[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       ...,\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]]], dtype=float32)], array([0, 0, 0, 1, 0, 0, 0, 0])).\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_218317]"],"ename":"InvalidArgumentError","evalue":"Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was ((tf.float32, tf.float32), tf.float32), but the yielded element was ([array([[[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       ...,\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]]], dtype=float32), array([[[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       ...,\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]]], dtype=float32)], array([0, 0, 0, 1, 0, 0, 0, 0])).\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 204, in generator_py_func\n    flattened_values = nest.flatten_up_to(output_types, values)\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 237, in flatten_up_to\n    return nest_util.flatten_up_to(\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py\", line 1541, in flatten_up_to\n    return _tf_data_flatten_up_to(shallow_tree, input_tree)\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py\", line 1570, in _tf_data_flatten_up_to\n    _tf_data_assert_shallow_structure(shallow_tree, input_tree)\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py\", line 1444, in _tf_data_assert_shallow_structure\n    _tf_data_assert_shallow_structure(\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py\", line 1414, in _tf_data_assert_shallow_structure\n    raise TypeError(\n\nTypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: 'list'.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 206, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was ((tf.float32, tf.float32), tf.float32), but the yielded element was ([array([[[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       ...,\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]]], dtype=float32), array([[[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       ...,\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]],\n\n       [[0.],\n        [0.],\n        [0.],\n        ...,\n        [0.],\n        [0.],\n        [0.]]], dtype=float32)], array([0, 0, 0, 1, 0, 0, 0, 0])).\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_218317]","output_type":"error"}],"execution_count":99},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f'Left images shape: {len(left_eye_images)}')\nprint(f'Right images shape: {len(right_eye_images)}')\nprint(f'Labels shape: {len(labels)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T11:46:53.787712Z","iopub.execute_input":"2024-11-03T11:46:53.788373Z","iopub.status.idle":"2024-11-03T11:46:53.793248Z","shell.execute_reply.started":"2024-11-03T11:46:53.788344Z","shell.execute_reply":"2024-11-03T11:46:53.792342Z"}},"outputs":[{"name":"stdout","text":"Left images shape: 6068\nRight images shape: 6068\nLabels shape: 6068\n","output_type":"stream"}],"execution_count":86},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}